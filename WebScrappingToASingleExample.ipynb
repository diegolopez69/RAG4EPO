{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lapto's headers: https://httpbin.org/anything\n",
    "headers =  {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\", \n",
    "    #\"Accept-Encoding\": \"gzip, deflate, br, zstd\", \n",
    "    \"Accept-Language\": \"en-US,en;q=0.9,es;q=0.8\", \n",
    "    \"Dnt\": \"1\", \n",
    "    #\"Host\": \"httpbin.org\", \n",
    "    \"Referer\": \"https://www.scraperapi.com/\", \n",
    "    \"Sec-Ch-Ua\": \"\\\"Google Chrome\\\";v=\\\"125\\\", \\\"Chromium\\\";v=\\\"125\\\", \\\"Not.A/Brand\\\";v=\\\"24\\\"\", \n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\", \n",
    "    \"Sec-Ch-Ua-Platform\": \"\\\"Windows\\\"\", \n",
    "    \"Sec-Fetch-Dest\": \"document\", \n",
    "    \"Sec-Fetch-Mode\": \"navigate\", \n",
    "    \"Sec-Fetch-Site\": \"cross-site\", \n",
    "    \"Sec-Fetch-User\": \"?1\", \n",
    "    \"Upgrade-Insecure-Requests\": \"1\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\", \n",
    "    \"X-Amzn-Trace-Id\": \"Root=1-665ec732-28d2172a4721ed726fc59ceb\"\n",
    "  }\n",
    "\n",
    "def get_page(an):\n",
    "    URL = f\"https://register.epo.org/smartSearch?query={an}\" #https://register.epo.org/smartSearch?query= #https://register.epo.org/application?number=EP\n",
    "    page = requests.get(URL,headers=headers)\n",
    "    return page.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_tabla(soup):\n",
    "    tablas = soup.find_all('table')\n",
    "    return tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_valores(texto):\n",
    "    # Extraer número de patente\n",
    "    patent = re.findall(r'<span class=\"highlight\">EP<span class=\"highlight\">(\\d+)</span></span>', texto)\n",
    "    if len(patent) == 0:\n",
    "        patent = ''\n",
    "    else:\n",
    "        patent = 'EP' + patent[0]\n",
    "\n",
    "    # Extraer nombre de la patente\n",
    "    patent_name = re.findall(r'</span></span> - (.*?)</a>', texto)\n",
    "    if len(patent_name) == 0:\n",
    "        patent_name = ''\n",
    "    else:\n",
    "        patent_name = patent_name[0].strip()  \n",
    "\n",
    "    # Extraer Status\n",
    "    status = re.findall(\"\"\"Status</td><td class=\"t2\" colspan=\"3\">.*?<br/>\"\"\", texto)\n",
    "    if len(status) == 0:\n",
    "        status = ''\n",
    "    else:\n",
    "        status = status[0]\n",
    "        status = status.replace(\"\"\"Status</td><td class=\"t2\" colspan=\"3\">\"\"\",\"\").replace('<br/>','').strip()\n",
    "\n",
    "    #Most Recent Event date\n",
    "    most_recent_event_date = re.findall(r'Most recent event.*?<td class=\"t2\">(.*?)</td>', texto, re.DOTALL)\n",
    "    if len(most_recent_event_date) == 0:\n",
    "        most_recent_event_date = ''\n",
    "    else:\n",
    "        most_recent_event_date = most_recent_event_date[0].strip()\n",
    "\n",
    "    #Most recent event\n",
    "    most_recent_event = re.findall(r'Most recent event.*?<td class=\"t3\">(.*?)</td>', texto, re.DOTALL)\n",
    "    if len(most_recent_event) == 0:\n",
    "        most_recent_event = ''\n",
    "    else:\n",
    "        most_recent_event = most_recent_event[0].replace('<br/>', '').replace('\\r\\n', '').replace('\\t', '').replace('\\xa0', ' ').strip()\n",
    "\n",
    "    #Divisional Applications\n",
    "    divisional_apps = re.findall(r'<td class=\"t2\" colspan=\"3\">(EP\\d+\\.\\d+)\\s*\\/\\s*<a.*?>(EP\\d+)</a>', texto)\n",
    "    divisional_dict = dict(divisional_apps)\n",
    "\n",
    "    # Parent Applications\n",
    "    parent_apps = re.findall(r'<td class=\"t2\" colspan=\"3\">(EP\\d+\\.\\d+)\\s*\\/\\s*<a.*?>(EP\\d+)</a>', texto)\n",
    "    parent_dict = dict(parent_apps)\n",
    "\n",
    "    # Extraer inventores\n",
    "    inventors = re.findall(r'<td class=\"t2\" colspan=\"3\">(\\d+)\\xa0/\\r\\n\\t(.*?)<br/>\\r\\n\\t(.*?)<br/>\\r\\n\\t(.*?)\\r\\n\\t  / (.*?)<br/>', texto)\n",
    "    inventors_dict = []\n",
    "    for inv in inventors:\n",
    "        inventor_info = {\n",
    "            'number': inv[0],\n",
    "            'name': inv[1],\n",
    "            'address': inv[2] + ', ' + inv[3],\n",
    "            'country': inv[4]\n",
    "        }\n",
    "        inventors_dict.append(inventor_info)\n",
    "\n",
    "    # Extraer publicaciones \n",
    "    publications = re.findall(r'<td class=\"th\">Type:\\r\\n\\s*</td>\\s*<td class=\"t2\" colspan=\"2\">(.*?)</td>\\s*<td class=\"th\">No.:</td>\\s*<td class=\"t2\" colspan=\"2\">(.*?)</td>\\s*<td class=\"th\">Date:</td>\\s*<td class=\"t2\" colspan=\"2\">(.*?)</td>\\s*<td class=\"th\">Language:</td>\\s*<td class=\"t2\" colspan=\"2\">(.*?)</td>', texto)\n",
    "    publications_list = []\n",
    "    for pub in publications:\n",
    "        # Extraer el texto del enlace si existe, o usar el texto plano si no hay enlace\n",
    "        type_text = re.search(r'>([^<]+)</a>$', pub[0])\n",
    "        if type_text:\n",
    "            pub_type = type_text.group(1).strip()\n",
    "        else:\n",
    "            pub_type = re.sub(r'\\xa0', ' ', pub[0]).strip()\n",
    "        publication_info = {\n",
    "            'type': pub_type,\n",
    "            'number': re.sub(r'<.*?>', '', pub[1]).strip(),\n",
    "            'date': pub[2].strip(),\n",
    "            'language': pub[3].strip()\n",
    "        }\n",
    "        publications_list.append(publication_info)\n",
    "\n",
    "    # Extraer clasificaciones IPC\n",
    "    ipc_pattern = r'IPC:\\s*</td>\\s*<td class=\"t2\">\\s*(.*?)\\s*</td>'\n",
    "    ipc_matches = re.findall(ipc_pattern, texto, re.DOTALL)\n",
    "    ipc_list = [re.sub(r'\\s+', ' ', ipc).strip() for ipc in ipc_matches]\n",
    "\n",
    "    # Extraer clasificaciones CPC\n",
    "    cpc_pattern = r'CPC:</td>\\s*<td class=\"t2\" colspan=\"2\">(.*?)</td>'\n",
    "    cpc_matches = re.findall(cpc_pattern, texto, re.DOTALL)\n",
    "    \n",
    "    cpc_list = []\n",
    "    for match in cpc_matches:\n",
    "        soup = BeautifulSoup(match, 'html.parser')\n",
    "        b_elements = soup.find_all('b') # Encontrar todos los elementos <b> dentro del bloque\n",
    "        \n",
    "        # Extraer el texto y limpiarlo\n",
    "        items = [elem.get_text().strip() for elem in b_elements]\n",
    "        print(\"Elementos encontrados:\", items)  # Depuración\n",
    "        cpc_list.extend(items)\n",
    "    \n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Patent': [patent],\n",
    "        'Patent_Name': [patent_name],\n",
    "        'Status': [status],\n",
    "        'Most_Recent_Event_Date': [most_recent_event_date],\n",
    "        'Most_Recent_Event': [most_recent_event],\n",
    "        'Divisional_applications': [json.dumps(divisional_dict)],\n",
    "        'Parent_applications': [json.dumps(parent_dict)],\n",
    "        'Inventors': [json.dumps(inventors_dict)],\n",
    "        'Publications': [json.dumps(publications_list)],\n",
    "        'IPC': [json.dumps(ipc_list)],\n",
    "        'CPC': [json.dumps(cpc_list)]\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extraer_valores(texto):    \n",
    "#     # Extraer clasificaciones IPC\n",
    "#     ipc_pattern = r'IPC:\\s*</td>\\s*<td class=\"t2\">\\s*(.*?)\\s*</td>'\n",
    "#     ipc_matches = re.findall(ipc_pattern, texto, re.DOTALL)\n",
    "#     ipc_list = [re.sub(r'\\s+', ' ', ipc).strip() for ipc in ipc_matches]\n",
    "\n",
    "#     # Extraer clasificaciones CPC\n",
    "#     cpc_pattern = r'CPC:</td>\\s*<td class=\"t2\" colspan=\"2\">(.*?)</td>'\n",
    "#     cpc_matches = re.findall(cpc_pattern, texto, re.DOTALL)\n",
    "    \n",
    "#     cpc_list = []\n",
    "#     for match in cpc_matches:\n",
    "#         soup = BeautifulSoup(match, 'html.parser')\n",
    "#         b_elements = soup.find_all('b') # Encontrar todos los elementos <b> dentro del bloque\n",
    "        \n",
    "#         # Extraer el texto y limpiarlo\n",
    "#         items = [elem.get_text().strip() for elem in b_elements]\n",
    "#         print(\"Elementos encontrados:\", items)  # Depuración\n",
    "#         cpc_list.extend(items)\n",
    "\n",
    "\n",
    "#     # Crear DataFrame\n",
    "#     df = pd.DataFrame({\n",
    "#         'IPC_Classifications': [json.dumps(ipc_list)],\n",
    "#         'CPC_Classifications': [json.dumps(cpc_list)]\n",
    "#     })\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos encontrados: ['A61K31/485 (EP,CN,US);', 'A61K9/0053 (US);', 'A61K9/16 (KR);', 'A61K9/1617 (EP,US);', 'A61K9/1652 (EP,US);', 'A61K9/20 (KR);', 'A61K9/2009 (US);', 'A61K9/2013 (EP,US);', 'A61K9/2018 (EP,US);', 'A61K9/2054 (EP,US);', 'A61K9/2077 (EP,US);', 'A61K9/2095 (EP,US);', 'A61K9/2866 (EP,US);', 'A61K9/48 (KR);', 'A61K9/70 (US);', 'A61P1/00 (EP);', 'A61P1/04 (EP);', 'A61P1/10 (EP);', 'A61P13/12 (EP);', 'A61P17/04 (EP);', 'A61P25/00 (EP);', 'A61P25/04 (EP);', 'A61P25/36 (EP);', 'A61P29/00 (EP);', 'A61P43/00 (EP)']\n",
      "      Patent                                        Patent_Name  \\\n",
      "0  EP1492505  PHARMACEUTICAL PREPARATION CONTAINING OXYCODON...   \n",
      "\n",
      "           Status Most_Recent_Event_Date  \\\n",
      "0  Patent revoked             26.05.2017   \n",
      "\n",
      "                            Most_Recent_Event  \\\n",
      "0  Lapse of the patent in a contracting state   \n",
      "\n",
      "                             Divisional_applications  \\\n",
      "0  {\"EP10176720.0\": \"EP2319496\", \"EP11177513.6\": ...   \n",
      "\n",
      "                                 Parent_applications  \\\n",
      "0  {\"EP10176720.0\": \"EP2319496\", \"EP11177513.6\": ...   \n",
      "\n",
      "                                           Inventors  \\\n",
      "0  [{\"number\": \"01\", \"name\": \"BR\\u00d6GMANN, Bian...   \n",
      "\n",
      "                                        Publications  \\\n",
      "0  [{\"type\": \"A2 Application without search repor...   \n",
      "\n",
      "                                                 IPC  \\\n",
      "0  [\"A61K9/16, A61K9/20, A61K9/22, A61K31/485<br/>\"]   \n",
      "\n",
      "                                                 CPC  \n",
      "0  [\"A61K31/485 (EP,CN,US);\", \"A61K9/0053 (US);\",...  \n"
     ]
    }
   ],
   "source": [
    "htmlContent = get_page(1492505)\n",
    "if(htmlContent and \"Just a moment...\" not in htmlContent):\n",
    "    soup = BeautifulSoup(htmlContent, 'html.parser')\n",
    "    mytable = extraer_tabla(soup)[0]    \n",
    "    texto_limpio = extraer_valores(str(mytable))\n",
    "    print(texto_limpio)\n",
    "else:\n",
    "    print(\"WebScrapping no disponible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patent</th>\n",
       "      <th>Patent_Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Most_Recent_Event_Date</th>\n",
       "      <th>Most_Recent_Event</th>\n",
       "      <th>Divisional_applications</th>\n",
       "      <th>Parent_applications</th>\n",
       "      <th>Inventors</th>\n",
       "      <th>Publications</th>\n",
       "      <th>IPC</th>\n",
       "      <th>CPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP1492505</td>\n",
       "      <td>PHARMACEUTICAL PREPARATION CONTAINING OXYCODON...</td>\n",
       "      <td>Patent revoked</td>\n",
       "      <td>26.05.2017</td>\n",
       "      <td>Lapse of the patent in a contracting state</td>\n",
       "      <td>{\"EP10176720.0\": \"EP2319496\", \"EP11177513.6\": ...</td>\n",
       "      <td>{\"EP10176720.0\": \"EP2319496\", \"EP11177513.6\": ...</td>\n",
       "      <td>[{\"number\": \"01\", \"name\": \"BR\\u00d6GMANN, Bian...</td>\n",
       "      <td>[{\"type\": \"A2 Application without search repor...</td>\n",
       "      <td>[\"A61K9/16, A61K9/20, A61K9/22, A61K31/485&lt;br/&gt;\"]</td>\n",
       "      <td>[\"A61K31/485 (EP,CN,US);\", \"A61K9/0053 (US);\",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patent                                        Patent_Name  \\\n",
       "0  EP1492505  PHARMACEUTICAL PREPARATION CONTAINING OXYCODON...   \n",
       "\n",
       "           Status Most_Recent_Event_Date  \\\n",
       "0  Patent revoked             26.05.2017   \n",
       "\n",
       "                            Most_Recent_Event  \\\n",
       "0  Lapse of the patent in a contracting state   \n",
       "\n",
       "                             Divisional_applications  \\\n",
       "0  {\"EP10176720.0\": \"EP2319496\", \"EP11177513.6\": ...   \n",
       "\n",
       "                                 Parent_applications  \\\n",
       "0  {\"EP10176720.0\": \"EP2319496\", \"EP11177513.6\": ...   \n",
       "\n",
       "                                           Inventors  \\\n",
       "0  [{\"number\": \"01\", \"name\": \"BR\\u00d6GMANN, Bian...   \n",
       "\n",
       "                                        Publications  \\\n",
       "0  [{\"type\": \"A2 Application without search repor...   \n",
       "\n",
       "                                                 IPC  \\\n",
       "0  [\"A61K9/16, A61K9/20, A61K9/22, A61K31/485<br/>\"]   \n",
       "\n",
       "                                                 CPC  \n",
       "0  [\"A61K31/485 (EP,CN,US);\", \"A61K9/0053 (US);\",...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_limpio['CPC_Classifications'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_limpio['IPC_Classifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EP10176720.0'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Acá se obtiene el id atómico para una divissional application\n",
    "\n",
    "# json_str = texto_limpio['Divisional_applications'][0]\n",
    "\n",
    "# # Convertir la cadena JSON en un diccionario de Python\n",
    "# json_dict = json.loads(json_str)\n",
    "\n",
    "# # Obtener el primer key del diccionario\n",
    "# primer_key = list(json_dict.keys())[0]\n",
    "\n",
    "# primer_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
